{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8760 Load Analysis \n",
    "## Purpose\n",
    "The goal of this code is to take 8760 .csv files from electrical system and analyze when and where the load is not being met. It was specifically designed with the output from the HOMER microgrid software in mind. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import pathlib\n",
    "from glob  import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "\n",
    "def count_consecutive_groups(df):\n",
    "    groups = (df['hour'].diff() != 1).cumsum()  # Identify consecutive groups\n",
    "    return len(groups.unique()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_26400\\1189129509.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_26400\\1189129509.py:63: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups)\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_26400\\1189129509.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_26400\\1189129509.py:63: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups)\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_26400\\1189129509.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_26400\\1189129509.py:63: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups)\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_26400\\1189129509.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_26400\\1189129509.py:63: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Hours with Capacity Shortage</th>\n",
       "      <th>Hours with Battery &lt;30%</th>\n",
       "      <th>Hours with Unmet Load</th>\n",
       "      <th>Days with Outages</th>\n",
       "      <th>Total Outages (Year)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0pctCapShortage.csv</td>\n",
       "      <td>NA</td>\n",
       "      <td>104</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-5pctCapShortage.csv</td>\n",
       "      <td>432</td>\n",
       "      <td>551</td>\n",
       "      <td>349</td>\n",
       "      <td>49</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5pctCapShort.csv</td>\n",
       "      <td>721</td>\n",
       "      <td>789</td>\n",
       "      <td>592</td>\n",
       "      <td>72</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7-5pctCapShortage.csv</td>\n",
       "      <td>987</td>\n",
       "      <td>1112</td>\n",
       "      <td>815</td>\n",
       "      <td>97</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    File Hours with Capacity Shortage  \\\n",
       "0    0pctCapShortage.csv                           NA   \n",
       "1  2-5pctCapShortage.csv                          432   \n",
       "2       5pctCapShort.csv                          721   \n",
       "3  7-5pctCapShortage.csv                          987   \n",
       "\n",
       "   Hours with Battery <30%  Hours with Unmet Load  Days with Outages  \\\n",
       "0                      104                     29                  7   \n",
       "1                      551                    349                 49   \n",
       "2                      789                    592                 72   \n",
       "3                     1112                    815                 97   \n",
       "\n",
       "   Total Outages (Year)  \n",
       "0                     7  \n",
       "1                    62  \n",
       "2                   101  \n",
       "3                   133  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load csv file file path \n",
    "dir_path = os.path.join(\n",
    "    pathlib.Path.home(),\n",
    "        'code-projects',\n",
    "        'load-8760'\n",
    "        )\n",
    "\n",
    "\n",
    "data_files = glob(os.path.join(dir_path,'*.csv'))\n",
    "\n",
    "#list to store all results\n",
    "\n",
    "results = []\n",
    "outages_day_hrs_comb=[]\n",
    "outages_per_day_comb=[]\n",
    "\n",
    "for data_path in data_files:\n",
    "    data = pd.read_csv(\n",
    "        data_path,\n",
    "        delimiter=',',\n",
    "        header= 0,\n",
    "        index_col='Time',\n",
    "        skiprows=1)\n",
    "     \n",
    "    data= data[data.index.notnull()]\n",
    "\n",
    "    data=data.reset_index() #Reset Index\n",
    "    data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
    "    data[\"hour\"] = data['Time'].map(lambda x: x.hour)\n",
    "    data[\"day\"] = data['Time'].map(lambda x: x.day)\n",
    "    data[\"month\"] = data['Time'].map(lambda x: x.month)\n",
    "    \n",
    "\n",
    "     #Initialize N/A\n",
    "    hours_shortage = 'NA'\n",
    "    hours_battery_shortage = 'NA'\n",
    "    hours_unmet_load = 'NA' \n",
    "    num_days_outages = 'NA' \n",
    "    outages_year = 'NA' \n",
    "    # filter  how many hours load not met (capacity shortage > 0)\n",
    "    if 'Capacity Shortage' in data.columns:\n",
    "        data['Capacity Shortage'] = data['Capacity Shortage'].astype(float) #first need to force column to convert to float \n",
    "        capacity_shortage_df = data[data['Capacity Shortage'] > 0 ]\n",
    "        hours_shortage = len(capacity_shortage_df)\n",
    "   \n",
    "\n",
    "    #Calculate how many hours annual load is unmet   #for Battery <30%\n",
    "    if 'Generic 1kWh Li-Ion State of Charge' in data.columns:\n",
    "        data['Generic 1kWh Li-Ion State of Charge'] = data['Generic 1kWh Li-Ion State of Charge'].astype(float)\n",
    "        battery_shortage_df = data[data['Generic 1kWh Li-Ion State of Charge'] < 30 ]\n",
    "        hours_battery_shortage = len(battery_shortage_df)\n",
    "    # To find hours with Unmet Electrical Load\n",
    "\n",
    "    if 'Unmet Electrical Load' in data.columns:\n",
    "        data['Unmet Electrical Load'] = data['Unmet Electrical Load'].astype(float)\n",
    "        unmet_load_df = data[data['Unmet Electrical Load'] > 0.01 ]\n",
    "        hours_unmet_load = len(unmet_load_df)\n",
    "    \n",
    "    hours_per_day = unmet_load_df.groupby(['month','day']).size()\n",
    "   )\n",
    "    #Calculate number of days with outages \n",
    "    num_days_outages = len(hours_per_day)\n",
    "    # Calulate number of outages per year\n",
    "    outages_year = count_consecutive_groups (unmet_load_df)\n",
    "    #Calculate number of distinct outages \n",
    "    outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups)\n",
    "    #complile a list of results \n",
    "    results.append ({\n",
    "         'File': os.path.basename(data_path),\n",
    "        'Hours with Capacity Shortage': hours_shortage,\n",
    "        'Hours with Battery <30%': hours_battery_shortage,\n",
    "        'Hours with Unmet Load': hours_unmet_load,\n",
    "        'Days with Outages': num_days_outages,\n",
    "        'Total Outages (Year)': outages_year\n",
    "    })\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Summary  results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month  day\n",
      "1      1      10\n",
      "       2       7\n",
      "       4       7\n",
      "       5      14\n",
      "       6       7\n",
      "       13      3\n",
      "2      3       4\n",
      "       8      12\n",
      "       9       9\n",
      "       10      7\n",
      "3      24      2\n",
      "       27     12\n",
      "       28      6\n",
      "4      8      10\n",
      "       9       6\n",
      "       11      3\n",
      "       29      1\n",
      "       30      6\n",
      "5      8      13\n",
      "       9       6\n",
      "       13      9\n",
      "       14      6\n",
      "       17     11\n",
      "       18     15\n",
      "       19      6\n",
      "6      17     14\n",
      "       18     13\n",
      "       19      6\n",
      "       25      4\n",
      "       26     18\n",
      "       27      6\n",
      "7      21      1\n",
      "       22      6\n",
      "8      2      19\n",
      "       3      20\n",
      "       4       6\n",
      "9      2       8\n",
      "       3      13\n",
      "       4       6\n",
      "       15     10\n",
      "       16      6\n",
      "       17      6\n",
      "       27     13\n",
      "       28      6\n",
      "       29      8\n",
      "       30      6\n",
      "10     11     11\n",
      "       12      6\n",
      "       18      1\n",
      "       29      4\n",
      "       30      7\n",
      "       31     10\n",
      "11     1       6\n",
      "       8      13\n",
      "       9      14\n",
      "       10      6\n",
      "       18      9\n",
      "       19      6\n",
      "       20     12\n",
      "       21     13\n",
      "       22      6\n",
      "       27      7\n",
      "       28      6\n",
      "12     1       9\n",
      "       2       6\n",
      "       4       3\n",
      "       5      17\n",
      "       6       7\n",
      "       19      6\n",
      "       22     11\n",
      "       23      6\n",
      "       25      3\n",
      "dtype: int64\n",
      "month  day\n",
      "1      1      1\n",
      "       2      1\n",
      "       4      1\n",
      "       5      2\n",
      "       6      1\n",
      "       13     1\n",
      "2      3      1\n",
      "       8      1\n",
      "       9      2\n",
      "       10     1\n",
      "3      24     1\n",
      "       27     1\n",
      "       28     1\n",
      "4      8      2\n",
      "       9      1\n",
      "       11     1\n",
      "       29     1\n",
      "       30     1\n",
      "5      8      3\n",
      "       9      1\n",
      "       13     2\n",
      "       14     1\n",
      "       17     1\n",
      "       18     3\n",
      "       19     1\n",
      "6      17     1\n",
      "       18     3\n",
      "       19     1\n",
      "       25     1\n",
      "       26     4\n",
      "       27     1\n",
      "7      21     1\n",
      "       22     1\n",
      "8      2      3\n",
      "       3      3\n",
      "       4      1\n",
      "9      2      1\n",
      "       3      3\n",
      "       4      1\n",
      "       15     1\n",
      "       16     1\n",
      "       17     1\n",
      "       27     1\n",
      "       28     1\n",
      "       29     2\n",
      "       30     1\n",
      "10     11     2\n",
      "       12     1\n",
      "       18     1\n",
      "       29     1\n",
      "       30     1\n",
      "       31     1\n",
      "11     1      1\n",
      "       8      1\n",
      "       9      2\n",
      "       10     1\n",
      "       18     1\n",
      "       19     1\n",
      "       20     3\n",
      "       21     2\n",
      "       22     1\n",
      "       27     1\n",
      "       28     1\n",
      "12     1      3\n",
      "       2      1\n",
      "       4      1\n",
      "       5      3\n",
      "       6      1\n",
      "       19     1\n",
      "       22     1\n",
      "       23     1\n",
      "       25     1\n",
      "dtype: int64\n",
      "Hours with Capacity Shortage= 721 hours\n",
      "Hours with Battery Capacity <30%=  789 hours\n",
      "# of Days with Outages (unmet load)=  72 days\n",
      "# of outages per year=  101 outages\n"
     ]
    }
   ],
   "source": [
    "\n",
    "summary_path = os.path.join(dir_path, 'shortage_summary_results.csv')\n",
    "results_df.to_csv(summary_path, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earth-analytics-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
