{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8760 Load Analysis \n",
    "## Purpose\n",
    "The goal of this code is to take 8760 .csv files from electrical systems and analyze when and where the load is not being met. It was specifically designed with the output from the HOMER microgrid software in mind. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from tkinter import Tk, filedialog, Label, Button, Entry, messagebox\n",
    "import seaborn as sns\n",
    "import os \n",
    "import pathlib\n",
    "from glob  import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define APP using class\n",
    "\n",
    "class HomerLoadAnalysis:\n",
    "    \n",
    "    \n",
    "    def get_files(self):\n",
    "        #Get the selected directory \n",
    "        dir_path= filedialog.askdirectory()\n",
    "        if not dir_path:\n",
    "            messagebox.showwarning(\"No Directory\", \"Please select a Folder\")\n",
    "            return\n",
    "        \n",
    "        #find all .csv files in the directory\n",
    "    \n",
    "        self.data_files = glob(os.path.join(dir_path,'*.csv'))\n",
    "        if not self.data_files:\n",
    "            messagebox.showerror(\"No Files\", \"No CSV Files found in the selected directory\")\n",
    "            return\n",
    "        \n",
    "        self.results_dir = os.path.join(dir_path, 'results')\n",
    "        os.makedirs(self.results_dir, exist_ok=True)\n",
    "\n",
    "        messagebox.showinfo(\"Files Selected\", f\"Found {len(self.data_files)} CSV files.\")\n",
    "\n",
    "    #Function  to process CSV Files\n",
    "    def process_files(self):\n",
    "    \n",
    "        if not self.data_files:\n",
    "            messagebox.showerror(\"No Files\", \"Please Select a folder First\")\n",
    "            return\n",
    "        \n",
    "        #function within functions \n",
    "        def count_consecutive_groups(df):\n",
    "            groups = (df['hour'].diff() != 1).cumsum()  # Identify consecutive groups\n",
    "            return len(groups.unique()) \n",
    "        \n",
    "        # define function for plotting heatmap from days \n",
    "\n",
    "        def plot_yearly_heatmap(outages_day):\n",
    "            outages_day['date'] = pd.to_datetime({\n",
    "            'year': 2000,  # Adjust the year if needed\n",
    "            'month': outages_day['month'],\n",
    "            'day': outages_day['day']\n",
    "        })\n",
    "\n",
    "            # Create a full-year calendar\n",
    "            full_year = pd.date_range(start='2000-01-01', end='2000-12-31')\n",
    "            full_year_df = pd.DataFrame({'date': full_year})\n",
    "            full_year_df['day_of_week'] = full_year_df['date'].dt.dayofweek\n",
    "            full_year_df['week'] = full_year_df['date'].dt.isocalendar().week\n",
    "\n",
    "            # Merge outages_day into the full year to align with calendar dates\n",
    "            full_year_df = full_year_df.merge(\n",
    "                outages_day[['date', '#_of_outages']],\n",
    "                on='date',\n",
    "                how='left'\n",
    "            )\n",
    "            full_year_df['#_of_outages'] = full_year_df['#_of_outages'].fillna(0)  # Fill missing values with 0\n",
    "\n",
    "            # Aggregate data to ensure unique combinations of week and day_of_week\n",
    "            full_year_df_agg = full_year_df.groupby(['week', 'day_of_week']).agg({'#_of_outages': 'sum'}).reset_index()\n",
    "\n",
    "            # Pivot the data for heat map structure\n",
    "            heatmap_data = full_year_df_agg.pivot(index='week', columns='day_of_week', values='#_of_outages')\n",
    "\n",
    "            #Title Heatmap based on file name\n",
    "            heatmap_title = 'Daily Outages Heat Map for ' + f\"{os.path.basename(data_path)}\" \n",
    "\n",
    "            # Plot the heat map\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            sns.heatmap(\n",
    "                heatmap_data,\n",
    "                cmap='cool',  # Color palette\n",
    "                linewidths=0.5,   # Grid lines\n",
    "                annot=False,      # Set True if you want annotations\n",
    "                cbar_kws={'label': 'Number of Outages'}\n",
    "            )\n",
    "            plt.title(heatmap_title, fontsize=16)\n",
    "            plt.xlabel('Day of the Week', fontsize=12)\n",
    "            plt.ylabel('Week of the Year', fontsize=12)\n",
    "            plt.xticks(ticks=np.arange(7), labels=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'], rotation=45)\n",
    "            plt.yticks(rotation=0)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Save the heat map\n",
    "            output_path = os.path.join(self.results_dir, f\"{os.path.basename(data_path)}_heatmap.png\")\n",
    "            plt.savefig(output_path)\n",
    "            plt.close()\n",
    "\n",
    "            return print(f\"Saved heat map for {data_path} to {self.results_dir}\")\n",
    "    \n",
    "        #list to store all results\n",
    "\n",
    "        results = []\n",
    "        outages_summary=[]\n",
    "\n",
    "\n",
    "        for data_path in self.data_files:\n",
    "            data = pd.read_csv(\n",
    "                data_path,\n",
    "                delimiter=',',\n",
    "                header= 0,\n",
    "                index_col='Time',\n",
    "                skiprows=1)\n",
    "            \n",
    "            data= data[data.index.notnull()]\n",
    "\n",
    "            data=data.reset_index() #Reset Index\n",
    "            data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
    "            data[\"hour\"] = data['Time'].map(lambda x: x.hour)\n",
    "            data[\"day\"] = data['Time'].map(lambda x: x.day)\n",
    "            data[\"month\"] = data['Time'].map(lambda x: x.month)\n",
    "            \n",
    "\n",
    "            #Initialize N/A\n",
    "            hours_shortage = '0'\n",
    "            hours_battery_shortage = '0'\n",
    "            hours_unmet_load = '0' \n",
    "            num_days_outages = '0' \n",
    "            outages_year = '0' \n",
    "            # filter  how many hours load not met (capacity shortage > 0)\n",
    "            if 'Capacity Shortage' in data.columns:\n",
    "                data['Capacity Shortage'] = data['Capacity Shortage'].astype(float) #first need to force column to convert to float \n",
    "                capacity_shortage_df = data[data['Capacity Shortage'] > 0 ]\n",
    "                hours_shortage = len(capacity_shortage_df)\n",
    "        \n",
    "\n",
    "            #Calculate how many hours annual load is unmet   #for Battery <30%\n",
    "            if 'Generic 1kWh Li-Ion State of Charge' in data.columns:\n",
    "                data['Generic 1kWh Li-Ion State of Charge'] = data['Generic 1kWh Li-Ion State of Charge'].astype(float)\n",
    "                battery_shortage_df = data[data['Generic 1kWh Li-Ion State of Charge'] < 30 ]\n",
    "                hours_battery_shortage = len(battery_shortage_df)\n",
    "\n",
    "            # To find hours with Unmet Electrical Load\n",
    "            if 'Unmet Electrical Load' in data.columns:\n",
    "                data['Unmet Electrical Load'] = data['Unmet Electrical Load'].astype(float)\n",
    "                unmet_load_df = data[data['Unmet Electrical Load'] > 0.01 ]\n",
    "                hours_unmet_load = len(unmet_load_df)\n",
    "            \n",
    "            hours_per_day = unmet_load_df.groupby(['month','day']).size().reset_index()\n",
    "            hours_per_day.columns=['month','day','hours_with_unmet_load']\n",
    "            #Calculate number of days with outages \n",
    "            num_days_outages = len(hours_per_day)\n",
    "            # Calulate number of outages per year\n",
    "            outages_year = count_consecutive_groups (unmet_load_df)\n",
    "            #Calculate number of distinct outages \n",
    "            outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n",
    "            outages_day.columns = ['month','day','#_of_outages']\n",
    "\n",
    "\n",
    "            #save heatmap for each file\n",
    "            plot_yearly_heatmap(outages_day)\n",
    "\n",
    "            #complile a list of results for summary \n",
    "            results.append ({\n",
    "                'File': os.path.basename(data_path),\n",
    "                'Hours with Capacity Shortage': hours_shortage,\n",
    "                'Hours with Battery <30%': hours_battery_shortage,\n",
    "                'SAIDI (hrs outages/year)': hours_unmet_load,\n",
    "                'Days with Outages': num_days_outages,\n",
    "                'SAIFI (outages/year)': outages_year,\n",
    "            \n",
    "            })\n",
    "\n",
    "            #Merge hours_per_day and outages_day data frames\n",
    "            if not hours_per_day.empty and not outages_day.empty:\n",
    "                merged = pd.merge(hours_per_day, outages_day, on=['month', 'day'], how='outer')\n",
    "                merged['File'] = os.path.basename(data_path)\n",
    "                outages_summary.append(merged)\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "        outages_summary_df = pd.concat(outages_summary, ignore_index=True)\n",
    "\n",
    "        summary_path = os.path.join(self.results_dir, 'outages_summary_results.csv')\n",
    "        results_df.to_csv(summary_path, index=False)\n",
    "\n",
    "        outages_daily_detail_path = os.path.join(self.results_dir,'outages_daily_details.csv')\n",
    "        outages_summary_df.to_csv(outages_daily_detail_path, index=False)\n",
    "\n",
    "        messagebox.showinfo(\"Processing Complete\", f\"Results saved to {self.results_dir}\")    \n",
    "\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"8760 Load Processor v.0.0.1\")\n",
    "        self.root.geometry(\"400x300\")\n",
    "\n",
    "        self.data_files = []\n",
    "\n",
    "        #directory selection box\n",
    "        Label(root, text=\"Select a Folder Containing 8760 CSV Files\").pack(pady=10)\n",
    "        Button(root, text=\"Select Folder\", command=self.get_files).pack(pady=5)\n",
    "\n",
    "        #Process Button \n",
    "        Button(root, text = \"Process Files\", command=self.process_files).pack(pady=20)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\10_results_P3.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\11_results_P3.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\12_results_P3.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\13_results_P3.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\14_results_P3.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\15_results_P3.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\16_results_P3.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\17_results_P3.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\18_results_P3.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\19_results_P3.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\1_results_NO.EC.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\20_results_P3.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\2_results.NO EC.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\3_results NO EC.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\4_results NO EC.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\5_results NO EC.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\6_results_P3.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\7_results_P3.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\8_results_P3.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
      "C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_2044\\2470458774.py:147: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved heat map for C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\9_results_P3.csv to C:/Users/Nolan Welsh/UCB-O365/Imanol Amundarain Arananburu - Project/Electric Cooking - Load management program/2 days ahead/HOMER results cvs\\results\n"
     ]
    }
   ],
   "source": [
    "# Run the GUI \n",
    "\n",
    "root = Tk()\n",
    "app=HomerLoadAnalysis(root)\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earth-analytics-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
