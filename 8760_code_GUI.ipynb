{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8760 Load Analysis \n",
    "## Purpose\n",
    "The goal of this code is to take 8760 .csv files from electrical systems and analyze when and where the load is not being met. It was specifically designed with the output from the HOMER microgrid software in mind. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from tkinter import Tk, filedialog, Label, Button, Entry, messagebox\n",
    "import seaborn as sns\n",
    "import os \n",
    "import pathlib\n",
    "from glob  import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Global Variables \n",
    "\n",
    "data_files = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for counting consecutive groups, for counting number of outages per day \n",
    "\n",
    "def count_consecutive_groups(df):\n",
    "    groups = (df['hour'].diff() != 1).cumsum()  # Identify consecutive groups\n",
    "    return len(groups.unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for plotting heatmap from days \n",
    "\n",
    "def plot_yearly_heatmap(outages_day):\n",
    "    outages_day['date'] = pd.to_datetime({\n",
    "    'year': 2000,  # Adjust the year if needed\n",
    "    'month': outages_day['month'],\n",
    "    'day': outages_day['day']\n",
    "})\n",
    "\n",
    "    # Create a full-year calendar\n",
    "    full_year = pd.date_range(start='2000-01-01', end='2000-12-31')\n",
    "    full_year_df = pd.DataFrame({'date': full_year})\n",
    "    full_year_df['day_of_week'] = full_year_df['date'].dt.dayofweek\n",
    "    full_year_df['week'] = full_year_df['date'].dt.isocalendar().week\n",
    "\n",
    "    # Merge outages_day into the full year to align with calendar dates\n",
    "    full_year_df = full_year_df.merge(\n",
    "        outages_day[['date', '#_of_outages']],\n",
    "        on='date',\n",
    "        how='left'\n",
    "    )\n",
    "    full_year_df['#_of_outages'] = full_year_df['#_of_outages'].fillna(0)  # Fill missing values with 0\n",
    "\n",
    "    # Aggregate data to ensure unique combinations of week and day_of_week\n",
    "    full_year_df_agg = full_year_df.groupby(['week', 'day_of_week']).agg({'#_of_outages': 'sum'}).reset_index()\n",
    "\n",
    "    # Pivot the data for heat map structure\n",
    "    heatmap_data = full_year_df_agg.pivot(index='week', columns='day_of_week', values='#_of_outages')\n",
    "\n",
    "    #Title Heatmap based on file name\n",
    "    heatmap_title = 'Daily Outages Heat Map for ' + f\"{os.path.basename(data_path)}\" \n",
    "\n",
    "    # Plot the heat map\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(\n",
    "        heatmap_data,\n",
    "        cmap='cool',  # Color palette\n",
    "        linewidths=0.5,   # Grid lines\n",
    "        annot=False,      # Set True if you want annotations\n",
    "        cbar_kws={'label': 'Number of Outages'}\n",
    "    )\n",
    "    plt.title(heatmap_title, fontsize=16)\n",
    "    plt.xlabel('Day of the Week', fontsize=12)\n",
    "    plt.ylabel('Week of the Year', fontsize=12)\n",
    "    plt.xticks(ticks=np.arange(7), labels=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'], rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the heat map\n",
    "    output_path = os.path.join(results_dir, f\"{os.path.basename(data_path)}_heatmap.png\")\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "    return print(f\"Saved heat map for {data_path} to {results_dir}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files():\n",
    "    #Get the selected directory \n",
    "    dir_path= filedialog.askdirectory()\n",
    "    if not dir_path:\n",
    "        messagebox.showwarning(\"No Directory\", \"Please select a Folder\")\n",
    "        return\n",
    "    \n",
    "    #find all .csv files in the directory\n",
    "    data_files = glob(os.path.join(dir_path,'*.csv'))\n",
    "    if not data_files:\n",
    "        messagebox.showerror(\"No Files\", \"No CSV Files found in the selected directory\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        #Get the number of customers\n",
    "        num_customers = 6\n",
    "        if num_customers <= 0:\n",
    "            raise ValueError(\"Number of customers must be greater than 0.\")\n",
    "    except ValueError as e:\n",
    "        messagebox.showerror(\"Invalid Input\", f\"Invalid number of customers: {e}\")\n",
    "        return\n",
    "\n",
    "  \n",
    "    # results directory for saving results\n",
    "    results_dir = os.path.join(dir_path, 'results')\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    return data_files\n",
    "    \n",
    "#Keep data files     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to use in GUI to process CSV Files\n",
    "def process_files():\n",
    "   \n",
    "    #list to store all results\n",
    "\n",
    "    results = []\n",
    "    outages_summary=[]\n",
    "\n",
    "\n",
    "    for data_path in data_files:\n",
    "        data = pd.read_csv(\n",
    "            data_path,\n",
    "            delimiter=',',\n",
    "            header= 0,\n",
    "            index_col='Time',\n",
    "            skiprows=1)\n",
    "        \n",
    "        data= data[data.index.notnull()]\n",
    "\n",
    "        data=data.reset_index() #Reset Index\n",
    "        data[\"Time\"] = pd.to_datetime(data[\"Time\"])\n",
    "        data[\"hour\"] = data['Time'].map(lambda x: x.hour)\n",
    "        data[\"day\"] = data['Time'].map(lambda x: x.day)\n",
    "        data[\"month\"] = data['Time'].map(lambda x: x.month)\n",
    "        \n",
    "\n",
    "        #Initialize N/A\n",
    "        hours_shortage = '0'\n",
    "        hours_battery_shortage = '0'\n",
    "        hours_unmet_load = '0' \n",
    "        num_days_outages = '0' \n",
    "        outages_year = '0' \n",
    "        # filter  how many hours load not met (capacity shortage > 0)\n",
    "        if 'Capacity Shortage' in data.columns:\n",
    "            data['Capacity Shortage'] = data['Capacity Shortage'].astype(float) #first need to force column to convert to float \n",
    "            capacity_shortage_df = data[data['Capacity Shortage'] > 0 ]\n",
    "            hours_shortage = len(capacity_shortage_df)\n",
    "    \n",
    "\n",
    "        #Calculate how many hours annual load is unmet   #for Battery <30%\n",
    "        if 'Generic 1kWh Li-Ion State of Charge' in data.columns:\n",
    "            data['Generic 1kWh Li-Ion State of Charge'] = data['Generic 1kWh Li-Ion State of Charge'].astype(float)\n",
    "            battery_shortage_df = data[data['Generic 1kWh Li-Ion State of Charge'] < 30 ]\n",
    "            hours_battery_shortage = len(battery_shortage_df)\n",
    "\n",
    "        # To find hours with Unmet Electrical Load\n",
    "        if 'Unmet Electrical Load' in data.columns:\n",
    "            data['Unmet Electrical Load'] = data['Unmet Electrical Load'].astype(float)\n",
    "            unmet_load_df = data[data['Unmet Electrical Load'] > 0.01 ]\n",
    "            hours_unmet_load = len(unmet_load_df)\n",
    "        \n",
    "        hours_per_day = unmet_load_df.groupby(['month','day']).size().reset_index()\n",
    "        hours_per_day.columns=['month','day','hours_with_unmet_load']\n",
    "        #Calculate number of days with outages \n",
    "        num_days_outages = len(hours_per_day)\n",
    "        # Calulate number of outages per year\n",
    "        outages_year = count_consecutive_groups (unmet_load_df)\n",
    "        #Calculate number of distinct outages \n",
    "        outages_day = unmet_load_df.groupby(['month', 'day']).apply(count_consecutive_groups).reset_index()\n",
    "        outages_day.columns = ['month','day','#_of_outages']\n",
    "\n",
    "\n",
    "        #save heatmap for each file\n",
    "        plot_yearly_heatmap(outages_day)\n",
    "\n",
    "        #complile a list of results for summary \n",
    "        results.append ({\n",
    "            'File': os.path.basename(data_path),\n",
    "            'Hours with Capacity Shortage': hours_shortage,\n",
    "            'Hours with Battery <30%': hours_battery_shortage,\n",
    "            'SAIDI (hrs outages/year)': hours_unmet_load,\n",
    "            'Days with Outages': num_days_outages,\n",
    "            'SAIFI (outages/year)': outages_year,\n",
    "        \n",
    "        })\n",
    "\n",
    "        #Merge hours_per_day and outages_day data frames\n",
    "        if not hours_per_day.empty and not outages_day.empty:\n",
    "            merged = pd.merge(hours_per_day, outages_day, on=['month', 'day'], how='outer')\n",
    "            merged['File'] = os.path.basename(data_path)\n",
    "            outages_summary.append(merged)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    outages_summary_df = pd.concat(outages_summary, ignore_index=True)\n",
    "\n",
    "    summary_path = os.path.join(results_dir, 'outages_summary_results.csv')\n",
    "    results_df.to_csv(summary_path, index=False)\n",
    "\n",
    "    outages_daily_detail_path = os.path.join(results_dir,'outages_daily_details.csv')\n",
    "    outages_summary_df.to_csv(outages_daily_detail_path, index=False)\n",
    "\n",
    "    messagebox.showinfo(\"Processing Complete\", f\"Results saved to {results_dir}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Nolan Welsh\\miniconda3\\envs\\earth-analytics-python\\Lib\\tkinter\\__init__.py\", line 1967, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Nolan Welsh\\AppData\\Local\\Temp\\ipykernel_38788\\4250798006.py\", line 84, in process_files\n",
      "    outages_summary_df = pd.concat(outages_summary, ignore_index=True)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Nolan Welsh\\miniconda3\\envs\\earth-analytics-python\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py\", line 382, in concat\n",
      "    op = _Concatenator(\n",
      "         ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Nolan Welsh\\miniconda3\\envs\\earth-analytics-python\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py\", line 445, in __init__\n",
      "    objs, keys = self._clean_keys_and_objs(objs, keys)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Nolan Welsh\\miniconda3\\envs\\earth-analytics-python\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py\", line 507, in _clean_keys_and_objs\n",
      "    raise ValueError(\"No objects to concatenate\")\n",
      "ValueError: No objects to concatenate\n"
     ]
    }
   ],
   "source": [
    "#Make GUI\n",
    "app = Tk()\n",
    "app.title(\"8760 Load Processor v.0.0.1\")\n",
    "app.geometry(\"400x300\")\n",
    "\n",
    "#directory selection box\n",
    "Label(app, text=\"Select a Folder Containing 8760 CSV Files\").pack(pady=10)\n",
    "Button(app, text=\"Select Folder\", command=get_files).pack(pady=5)\n",
    "\n",
    "#number of customers input \n",
    "Label(app, text=\"Enter number of customers\").pack(pady=10)\n",
    "num_customer_entry = Entry(app)\n",
    "num_customer_entry.pack(pady=5)\n",
    "\n",
    "#Process Button \n",
    "Button(app, text = \"Process Files\", command=process_files).pack(pady=20)\n",
    "\n",
    "#Run the program \n",
    "app.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earth-analytics-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
